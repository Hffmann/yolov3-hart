{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 12:17:08.304951 11400 __init__.py:690] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n",
      "W1003 12:17:08.539323 11400 module_wrapper.py:137] From C:\\Python\\hart-master\\neurocity\\data\\data_runner.py:30: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "'''\n",
    "from scipy.misc import imread, imresize\n",
    "'''\n",
    "import cv2\n",
    "\n",
    "from hart.data import disp\n",
    "from hart.data.kitti.tools import get_data\n",
    "from hart.model import util\n",
    "from hart.model.attention_ops import FixedStdAttention\n",
    "from hart.model.eval_tools import log_norm, log_ratios, log_values, make_expr_logger\n",
    "from hart.model.tracker import HierarchicalAttentiveRecurrentTracker as HART\n",
    "from hart.model.nn import AlexNetModel, IsTrainingLayer\n",
    "from hart.train_tools import TrainSchedule, minimize_clipped\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(img_dir):\n",
    "    img_paths = sorted(os.listdir(img_dir))\n",
    "    imgs = np.empty([len(img_paths), 1] + list(img_size), dtype=np.float32)\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        img_path= os.path.join(img_dir, img_path)\n",
    "        \n",
    "        imgs[i, 0] = cv2.imread(img_path)\n",
    "        imgs[i, 0] = cv2.resize(imgs[i, 0], img_size[:2])\n",
    "        '''\n",
    "        imgs[i, 0] = imresize(imread(img_path), img_size[:2])\n",
    "        '''\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_dir = 'checkpoints'\n",
    "img_dir = 'imgs'\n",
    "# checkpoint_path = 'checkpoints/kitti/pretrained/2017_07_06_16.41/model.ckpt-142320'\n",
    "checkpoint_path = 'checkpoints/kitti/pretrained/model.ckpt-347346'\n",
    "\n",
    "batch_size = 1\n",
    "img_size = 187, 621, 3\n",
    "crop_size = 56, 56, 3\n",
    "\n",
    "rnn_units = 100\n",
    "norm = 'batch'\n",
    "keep_prob = .75\n",
    "\n",
    "img_size, crop_size = [np.asarray(i) for i in (img_size, crop_size)]\n",
    "keys = ['img', 'bbox', 'presence']\n",
    "\n",
    "bbox_shape = (1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1003 12:17:09.581536 11400 deprecation.py:323] From C:\\Python\\hart-master\\hart\\model\\attention_ops.py:300: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1003 12:17:09.669326 11400 deprecation.py:323] From C:\\Python\\hart-master\\hart\\model\\attention_ops.py:44: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1003 12:17:09.691243 11400 deprecation.py:506] From C:\\Python\\hart-master\\hart\\model\\attention_ops.py:61: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1003 12:17:09.742106 11400 deprecation.py:506] From C:\\Python\\hart-master\\hart\\model\\tensor_ops.py:80: calling reduce_min_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1003 12:17:09.744101 11400 deprecation.py:506] From C:\\Python\\hart-master\\hart\\model\\tensor_ops.py:81: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1003 12:17:10.319564 11400 deprecation.py:323] From C:\\Python\\hart-master\\neurocity\\component\\layer.py:203: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1003 12:17:10.322554 11400 deprecation.py:506] From C:\\Python\\hart-master\\neurocity\\component\\layer.py:205: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1003 12:17:10.332553 11400 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1003 12:17:10.520027 11400 deprecation.py:323] From C:\\Python\\hart-master\\hart\\model\\tracker.py:93: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W1003 12:17:11.280990 11400 deprecation.py:323] From C:\\SPB_Data\\.conda\\envs\\keras_tf\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W1003 12:17:11.659977 11400 module_wrapper.py:137] From C:\\Python\\hart-master\\hart\\model\\tracker.py:99: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "util.set_random_seed(0)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, batch_size] + list(img_size), name='image')\n",
    "y0 = tf.placeholder(tf.float32, bbox_shape, name='bbox')\n",
    "p0 = tf.ones(y0.get_shape()[:-1], dtype=tf.uint8, name='presence')\n",
    "\n",
    "is_training = IsTrainingLayer()\n",
    "builder = AlexNetModel(alexnet_dir, layer='conv3', n_out_feature_maps=5, upsample=False, normlayer=norm,\n",
    "                       keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "model = HART(x, y0, p0, batch_size, crop_size, builder, rnn_units,\n",
    "             bbox_gain=[-4.78, -1.8, -3., -1.8],\n",
    "             zoneout_prob=(.05, .05),\n",
    "             normalize_glimpse=True,\n",
    "             attention_module=FixedStdAttention,\n",
    "             debug=True,\n",
    "             transform_init_features=True,\n",
    "             transform_init_state=True,\n",
    "             dfn_readout=True,\n",
    "             feature_shape=(14, 14),\n",
    "             is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, checkpoint_path)\n",
    "model.test_mode(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (188,621,3) into shape (187,621,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5d41dde96b1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0f9efbddd31c>\u001b[0m in \u001b[0;36mload_imgs\u001b[1;34m(img_dir)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         '''\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (188,621,3) into shape (187,621,3)"
     ]
    }
   ],
   "source": [
    "imgs = load_imgs(img_dir)\n",
    "bbox = [88, 250, 18, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x: imgs, y0: np.reshape(bbox, bbox_shape)}\n",
    "tensors = [model.pred_bbox, model.att_pred_bbox, model.glimpse, model.obj_mask]\n",
    "pred_bbox, pred_att, glimpse, obj_mask = sess.run(tensors, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = imgs.shape[0]\n",
    "fig, axes = plt.subplots(n, 3, figsize=(20, 2*n))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax[0].imshow(imgs[i].squeeze() / 255.)\n",
    "    ax[1].imshow(glimpse[i].squeeze())\n",
    "    ax[2].imshow(obj_mask[i].squeeze(), cmap='gray', vmin=0., vmax=1.)\n",
    "    disp.rect(pred_bbox[i].squeeze(), 'b', ax=ax[0])\n",
    "    disp.rect(pred_att[i].squeeze(), 'g', ax=ax[0])\n",
    "    for a in ax:\n",
    "        a.xaxis.set_visible(False)\n",
    "        a.yaxis.set_visible(False)\n",
    "        \n",
    "axes[0, 0].plot([], c='g', label='att')\n",
    "axes[0, 0].plot([], c='b', label='pred')\n",
    "axes[0, 0].legend(loc='center right')\n",
    "axes[0, 0].set_xlim([0, img_size[1]])\n",
    "axes[0, 0].set_ylim([img_size[0], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
